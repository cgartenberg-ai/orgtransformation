# Current Mechanisms

These mechanisms emerged from systematic case analysis. Each represents a structural practice observed across multiple organizations that addresses the exploration/execution tension.

## Confirmed Mechanisms

### 1. Protect Off-Strategy Work
**Definition**: Organizational structures that shield exploratory work ("deviations") from middle management's natural tendency to optimize for current strategy.

**Problem it solves**: Middle management rationally kills deviations because they don't fit current metrics. But deviations create breakthroughs.

**Key specimens**: Eli Lilly (Dave Ricks: "Middle management tends to squash deviations, but the deviations... make the next breakthrough")

**Theoretical connection**: Structural ambidexterity — physical separation protects exploration from exploitation pressures.

---

### 2. Bonus Teams That Kill Projects
**Definition**: Incentive systems that reward teams for quickly terminating their own projects when evidence shows they won't work.

**Problem it solves**: Sunk cost fallacy keeps failing projects alive too long, wasting exploration resources.

**Key specimens**: Google X (teams get "applause, hugs, and high fives" for killing projects; 2% graduation rate by design)

**Theoretical connection**: Addresses temporal dimension — fast failure enables more exploration cycles.

---

### 3. Embed Product at Research Frontier
**Definition**: Product teams working directly with researchers on model development, not downstream building UX on finished models.

**Problem it solves**: Value multiplier comes from frontier proximity. Downstream product work captures less of the innovation value.

**Key specimens**: Anthropic (Labs Team explores early computer use, CLI prototypes; Claude Code went from internal experiment to dominant tool in 3 months)

**Theoretical connection**: Integration mechanism — bridges exploration (research) and execution (product).

---

### 4. Consumer-Grade UX for Employee Tools
**Definition**: Extending consumer-proven interfaces to employees rather than building separate enterprise systems.

**Problem it solves**: Enterprise tools often have poor UX, limiting adoption. Consumer UX is already validated at scale.

**Key specimens**: Bank of America (Erica chatbot for customers → Erica for Employees; 90%+ adoption among 213K employees)

**Theoretical connection**: Reduces friction in contextual ambidexterity — individuals adopt faster when tools are intuitive.

---

### 5. Deploy to Thousands Before You Know What Works
**Definition**: Wide deployment of general-purpose AI to discover use cases, rather than narrow pilots to validate predetermined use cases.

**Problem it solves**: You can't predict which teams will find breakthrough applications. Pilots throttle learning.

**Key specimens**: P&G (8,000 requests in first two hours; rejected pilots), Commonwealth Bank (50,000 employees on day one)

**Theoretical connection**: Contextual ambidexterity at scale — let individuals find explore/execute balance.

---

### 6. Merge Competing AI Teams Under Single Leader
**Definition**: Consolidating multiple elite AI teams under unified leadership when coordination costs exceed independence benefits.

**Problem it solves**: Parallel teams duplicate infrastructure, compete for talent, create confusion about ownership.

**Key specimens**: Google (merged Brain and DeepMind under Hassabis), Tencent (unified AI under Chief AI Scientist reporting to CEO)

**Theoretical connection**: Structural simplification — from multiple exploration units to unified structure.

---

### 7. Put Executives on the Tools
**Definition**: Senior leaders spending significant time (8+ hours/week) personally using AI tools on real work, not just watching demos.

**Problem it solves**: Executives who don't use AI make bad decisions about AI. They can't evaluate structural options they don't understand.

**Key specimens**: BCG "Trailblazer" CEOs, Nadella restructuring Microsoft executives to work as ICs on AI, Mercado Libre founder stepping down as CEO to focus hands-on on AI

**Theoretical connection**: Leadership bridging — senior team holds explore/execute tension through direct experience.

---

### 8. Log Everything When Regulators Watch
**Definition**: Building complete audit trails into AI architecture from day one in regulated industries.

**Problem it solves**: Regulatory compliance looks like overhead but becomes competitive advantage — you can deploy AI that competitors can't.

**Key specimens**: Allianz (logs all Claude interactions), UBS (CAIO prioritizes "Explainable AI")

**Theoretical connection**: Enabling execution in constrained environments — structural accommodation of regulatory requirements.

---

### 9. Hire CAIOs from Consumer Tech
**Definition**: Prioritizing consumer tech product experience over enterprise IT background when hiring Chief AI Officers.

**Problem it solves**: AI transformation requires people who've shipped products to millions, not managed infrastructure.

**Key specimens**: UK Government CAIO (from Spotify/Facebook), Siemens (hired AWS VP for "consumer mindset")

**Theoretical connection**: Leadership selection — product mindset enables exploration; IT mindset optimizes execution.

---

### 10. Productize Internal Operational Advantages
**Definition**: Turning internally-developed AI tools into external revenue streams.

**Problem it solves**: Internal tools prove value; external sales extend advantage and create defensible moats.

**Key specimens**: Walmart (Route Optimization → Franz Edelman Award → GoLocal SaaS), Salesforce (2.6M internal conversations → Agentforce for 18,500 customers)

**Theoretical connection**: 5c Platform-to-Product model — execution capability becomes exploration of new business.

---

## Candidate Mechanisms (Under Observation)

These patterns have been observed but need more evidence before confirmation.

### Candidate: Ring-Fence Multi-Year Budgets
**Observed in**: Pharma AI labs, some tech moonshot factories
**Hypothesis**: Protecting exploration budgets from annual reallocation pressure enables longer time horizons
**Evidence needed**: More specimens showing budget protection mechanisms

### Candidate: Separate Reporting Lines for Exploration
**Observed in**: Various specimens
**Hypothesis**: Exploration units that report to CEO/board rather than COO/operations are more protected
**Evidence needed**: Systematic comparison of reporting structures and outcomes

### Candidate: Time-Box Then Reintegrate
**Observed in**: Tiger team models (Samsung C-Lab, others)
**Hypothesis**: Temporary structural separation followed by planned reintegration captures benefits of both
**Evidence needed**: More specimens with explicit reintegration mechanisms
