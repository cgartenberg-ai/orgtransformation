# Ambidexterity in the AI Era: A Field Guide
## Product Specification v1.4
### Updated February 12, 2026

---

## 1. The Botanist's Lens

This is a **field guide**, not a framework.

Where consulting frameworks tell leaders what they should do, a field guide documents what organizations actually do. Like a botanical field guide that catalogs plant species with detailed descriptions, habitat notes, and identification markers, this resource catalogs organizational specimens — real companies navigating the exploration/execution tension in the AI era.

**The Botanist's Job:**
- Observe organizational specimens in their natural habitat
- Document structural forms with rich, sourced detail
- Classify specimens by their characteristics
- Note the conditions under which each form thrives
- Let patterns emerge from careful observation

**What This Is Not:**
- A maturity model or scoring system
- A prescriptive methodology
- A consulting framework with "best practices"
- A tool that tells leaders what to do

---

## 2. The Core Tension

Every organization faces the same fundamental challenge: **how to simultaneously explore new possibilities while executing on current commitments**.

This is the ambidexterity challenge, first articulated by organizational scholars studying how firms survive technological disruption. In the AI era, this tension has become acute:

- **Exploration**: Experimenting with AI capabilities, developing new offerings, building for an uncertain future
- **Execution**: Running the business, serving existing customers, delivering on current commitments with operational excellence

The danger: organizations that focus only on execution become efficient but obsolete; those that focus only on exploration never capture value from their innovations.

**The Central Question:**
*How do organizations structurally enable both exploration and execution in the AI era?*

---

## 3. Theoretical Foundation

This field guide draws on organizational ambidexterity research, particularly the work of Charles O'Reilly and Michael Tushman, while remaining accessible to practitioners.

*Note on language: The academic literature uses "exploitation" to describe leveraging existing capabilities. We use "execution" for clarity — it captures the same concept (running the business, delivering on commitments) without the negative connotations.*

**Key Insight from the Literature:**
Sustained organizational success requires managing the exploration/execution tension. Different structural arrangements enable different approaches to this tension.

**Three Broad Approaches (from the literature):**

1. **Structural Ambidexterity**: Physically separate exploration and execution into different organizational units, with integration happening at senior leadership levels

2. **Contextual Ambidexterity**: Create organizational contexts where individuals can make their own judgments about when to explore vs. execute within their roles

3. **Sequential Ambidexterity**: Organizations cycle between periods of exploration and execution over time

This field guide focuses primarily on **structural approaches** — how organizations create, protect, and integrate structures that enable both AI-driven exploration and operational execution.

---

## 4. The Taxonomy

The taxonomy builds on empirical research originally documenting 285+ organizational cases. Specimens are continuously curated and classified along two dimensions: **primary structural model** and **ambidexterity orientation**. See `APP_STATE.md` for current specimen count and model distribution.

### Dimension 1: Structural Model
*What is the organizational structure for AI?*

Based on systematic observation of how organizations actually structure AI work:

| Model | Mission | Time Horizon | Ambidexterity Implication |
|-------|---------|--------------|---------------------------|
| **1. Research Lab** | Fundamental research, breakthroughs | 3-10 years | Pure exploration, structurally separated |
| **2. Center of Excellence** | Governance, standards, enablement | 6-24 months | Enables execution across organization |
| **3. Embedded Teams** | Product-specific AI features | Quarterly | Exploration integrated into execution |
| **4. Hybrid/Hub-and-Spoke** | Central standards + distributed execution | Mixed | Structural attempt to enable both |
| **5. Product/Venture Lab** | Commercialize AI into products | 6-36 months | Exploration with explicit path to value |
| **6. Unnamed/Informal** | Quiet transformation without formal structure | Varies | Often individual-level ambidexterity |
| **7. Tiger Teams** | Time-boxed exploration sprints | Weeks to months | Temporary structural separation, then reintegration |
| **8. Skunkworks** *(Emerging)* | Autonomous unit with radical independence | Years | Extreme structural separation, minimal parent oversight |
| **9. AI-Native** | Born-AI organization, no legacy to transform | Varies | No ambidexterity tension — the product IS exploration |

**Model 5 Sub-Types:**
- **5a. Internal Incubator** — Products absorbed into parent company (Adobe Firefly)
- **5b. Venture Builder** — Creates independent companies (Google X → Waymo)
- **5c. Platform-to-Product** — Internal capability sold externally (Walmart GoLocal)

**Model 6 Sub-Types:**
- **6a. Enterprise-Wide Adoption** — Mass deployment, 80%+ adoption (BofA 95% AI usage)
- **6b. Centralized-but-Unnamed** — Central team without lab branding (P&G ChatPG)
- **6c. Grassroots/Bottom-Up** — Adoption preceded formal structure ("secret cyborg" patterns)

*Key insight*: Research focused only on named labs (Models 1-5) systematically underestimates AI's organizational transformation. Model 6 captures the "quiet transformation" that may represent the majority of enterprise AI adoption.

### Dimension 2: Ambidexterity Orientation
*How does the organization balance exploration and execution?*

| Orientation | Description | Characteristic Pattern |
|-------------|-------------|----------------------|
| **Structural** | Exploration and execution in distinct units | Ring-fenced budgets, different reporting lines, protected time horizons |
| **Contextual** | Individuals balance exploration/execution within roles | "Prove AI can't do it" mandates, AI proficiency as baseline expectation |
| **Temporal** | Organization cycles between exploration and execution phases | Sprints, time-boxed experiments, phased transitions |

These three orientations come directly from the ambidexterity literature. Most specimens will exhibit one dominant orientation, though combinations occur.

### Classification Examples

**Eli Lilly**
- **Structural Model**: Model 4 (Hub-and-Spoke) + secondary Model 5b (Venture Builder with NVIDIA)
- **Ambidexterity Orientation**: Structural
- *Key pattern*: Decentralized 300-400 person hubs coordinated by central R&D leadership, 18-year time horizons, CEO protects "off-strategy" deviations. Reclassified from M1 to M4 — multiple distributed hubs with central coordination is Hub-and-Spoke, not a single Research Lab.

**Shopify**
- **Structural Model**: Model 3 (Embedded Teams)
- **Ambidexterity Orientation**: Contextual
- *Key pattern*: "Prove AI can't do it" mandate, AI proficiency as employment condition, CEO-driven cultural change

**Bank of America**
- **Structural Model**: Model 6a (Enterprise-Wide Adoption)
- **Ambidexterity Orientation**: Contextual
- *Key pattern*: Consumer-grade UX (Erica) extended to employees, 95% daily AI usage

**Google X**
- **Structural Model**: Model 5b (Venture Builder)
- **Ambidexterity Orientation**: Structural
- *Key pattern*: 100+ experiments annually, 2% graduation rate, teams bonused for killing projects

**Samsung C-Lab**
- **Structural Model**: Model 5a (Internal Incubator)
- **Ambidexterity Orientation**: Temporal
- *Key pattern*: Permanent 13-year incubator with 959 ventures. Employees leave roles for full-year dedicated exploration, 20% spin off into independent companies. Reclassified from M7 to M5a — a permanent institutional program is not an ad hoc tiger team.

---

## 5. The Specimen Card

Each organizational specimen is documented with a standard structure:

```
┌─────────────────────────────────────────────────────────────────┐
│  SPECIMEN: [Company Name]                                       │
│  Classification: [Structural Form] / [Integration Mechanism]    │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  DESCRIPTION                                                    │
│  What does this organization's ambidexterity structure          │
│  actually look like? Detailed narrative description.            │
│                                                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  STRUCTURAL MECHANISMS                                          │
│  Specific practices that make this form work:                   │
│  • [Mechanism 1 with evidence]                                  │
│  • [Mechanism 2 with evidence]                                  │
│  • [Mechanism 3 with evidence]                                  │
│                                                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  OBSERVABLE MARKERS                                             │
│  How you'd recognize this form in the wild:                     │
│  • Reporting structures                                         │
│  • Resource allocation patterns                                 │
│  • Time horizons                                                │
│  • Decision rights                                              │
│  • Metrics — KPIs the organization announces it tracks,         │
│    with specific targets, numbers, and framing                  │
│  (All facts include [source-id] citations for auditability)     │
│                                                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  HABITAT CONDITIONS                                             │
│  Conditions under which this form appears to thrive:            │
│  • Industry context                                             │
│  • Organizational characteristics                               │
│  • Leadership factors                                           │
│                                                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  QUOTES & EVIDENCE                                              │
│  Direct quotes from leaders, specific metrics, dated sources    │
│                                                                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  SOURCES                                                        │
│  Primary sources with URLs and dates                            │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 6. The Herbarium: Collection and Curation

A herbarium is a systematic collection of preserved plant specimens, organized for study. Each specimen includes not just the plant itself, but **collection data**: who found it, when, where, under what conditions. This provenance is as important as the specimen.

Our organizational herbarium follows the same principles.

### Extended Metaphors

| Natural History Term | Our Equivalent |
|---------------------|----------------|
| **Herbarium** | The complete collection of organizational specimens |
| **Field work** | Research phase — scanning sources, gathering raw observations |
| **Collection data** | Source provenance — where each fact came from, when |
| **Curation** | Classification phase — applying taxonomy, structuring specimens |
| **Type specimen** | The clearest example of a structural model (e.g., Google X for Venture Builder) |
| **Morphology** | Observable characteristics at a point in time |
| **Stratigraphy** | Historical layers — how an organization's approach evolved over time |
| **Convergent evolution** | Different organizations arriving at similar structures independently |
| **Adaptive radiation** | Variations emerging from a common structural ancestor |

### The Three-Phase Workflow

```
┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
│   FIELD WORK    │ ──▶ │    CURATION     │ ──▶ │    SYNTHESIS    │
│   (Research)    │     │ (Classification)│     │   (Patterns)    │
└─────────────────┘     └─────────────────┘     └─────────────────┘
        │                       │                       │
   Gather wide &           Apply taxonomy          Identify cross-
   deep observations       to specimens            cutting patterns
```

**Phase 1: Field Work (Research)**
- Scan sources systematically (see research/sources.md)
- Gather observations about organizations — wide (many orgs) and deep (specifics about each)
- Record raw findings with full source provenance
- No classification yet — just observation
- *Detailed workflow: skills/ambidexterity-research/SKILL.md*

**Phase 2: Curation (Classification)**
- Apply the 9-model taxonomy to each organization
- Assign ambidexterity orientation
- Structure findings into specimen cards
- Link to relevant mechanisms
- Flag organizations that don't fit cleanly (edge cases inform taxonomy evolution)
- *Detailed workflow: skills/ambidexterity-curation/SKILL.md*

**Phase 3: Synthesis (Patterns)**
- Identify mechanisms that appear across multiple specimens
- Note convergent evolution — different orgs arriving at similar solutions
- Surface tensions and trade-offs within models
- Update mechanism descriptions with new examples
- *Detailed workflow: skills/ambidexterity-synthesis/SKILL.md*

### Collection Principles

**1. No Information Lost (Stratigraphy)**

Organizations evolve. When an org changes its approach, the old approach is not overwritten — it becomes a historical layer.

```
SPECIMEN: Eli Lilly
├── 2026-01 Layer: Model 1 + 5b (NVIDIA partnership announced)
├── 2025-06 Layer: Model 1 (decentralized hubs)
└── 2023-xx Layer: [earlier structure if documented]
```

Each layer includes:
- Date observed (when we documented it)
- Date revealed (when the org announced/disclosed it)
- What changed from previous layer

**2. Source Provenance**

Every fact must be traceable to its original source. Collection data for each observation:

```
| Fact | Source | Source Date | Collected |
|------|--------|-------------|-----------|
| "300-400 person hubs" | Cheeky Pint podcast, Dave Ricks interview | 2025-11-xx | 2025-12-15 |
| "$1B NVIDIA partnership" | NVIDIA press release | 2026-01-12 | 2026-01-13 |
| "18-year GLP-1 program" | Chief Executive Magazine | 2025-xx-xx | 2025-12-15 |
```

**3. Temporal Markers**

All information carries two timestamps:
- **As-of date**: When the organization revealed/disclosed this information
- **Collection date**: When we captured it in the herbarium

This allows us to understand both the organization's timeline and our research timeline.

### Tracking Infrastructure

**Source Registry** — What we've scanned, through when:

```
| Source | Type | Last Scanned | Through | Notes |
|--------|------|--------------|---------|-------|
| No Priors | Podcast | 2026-01-15 | Ep 127 | Jensen Huang episode |
| Stratechery | Substack | 2026-01-20 | "AI and Enterprise" | |
| TechCrunch | Press | 2026-01-18 | search: "AI lab" | 47 results reviewed |
```

**Specimen Registry** — Collection status for each organization:

```
| Organization | Status | Created | Last Updated | Layer Count | Completeness |
|--------------|--------|---------|--------------|-------------|--------------|
| Eli Lilly | Active | 2025-12 | 2026-01-12 | 2 | High |
| P&G | Active | 2025-11 | 2025-11-20 | 1 | Medium |
| Acme Corp | Stub | 2026-01-05 | 2026-01-05 | 1 | Low |
```

Completeness levels:
- **High**: Multiple sources, specific mechanisms documented, quotes/metrics
- **Medium**: Core structure understood, some gaps in detail
- **Low/Stub**: Identified as relevant, insufficient detail yet

---

## 7. Site Structure

The reference site is organized for browsing and discovery:

### Home
- Brief introduction to the field guide concept
- The core exploration/execution tension
- How to use the guide

### Taxonomy
- Explanation of classification dimensions
- Visual matrix of Structural Form × Integration Mechanism
- Clickable to filter specimens

### Specimens
- Browsable collection of organizational specimens
- Filter by: Structural Form, Integration Mechanism, Industry
- Each specimen card expandable to full detail

### Principles (Mechanisms)
Cross-cutting patterns observed across multiple specimens. After a rigorous audit (Feb 3, 2026), the following **confirmed mechanisms** remain, each with scholarly anchors grounding them in organizational economics (see `synthesis/mechanisms.json` for current confirmed and candidate lists):

1. **Protect Off-Strategy Work** — Structure to let deviations survive. *Scholarly anchor: March (1991) on exploitation driving out exploration.* (Eli Lilly)
3. **Embed Product at Research Frontier** — Product teams work directly with researchers. *Scholarly anchor: Henderson & Clark (1990) on architectural innovation.* (Anthropic)
4. **Consumer-Grade UX for Employee Tools** — Extend consumer interfaces internally. *Scholarly anchor: Eisenhardt & Martin (2000) on dynamic capabilities.* (Bank of America)
5. **Deploy to Thousands Before You Know What Works** — Cast wide, then concentrate. *Scholarly anchor: Arrow (1962) on learning-by-doing.* (P&G, Commonwealth Bank)
6. **Merge Competing AI Teams Under Single Leader** — Consolidate when coordination costs exceed independence benefits. *Scholarly anchor: Gibbons & Henderson (2012) on relational contracts.* (Google DeepMind)
7. **Put Executives on the Tools** — Leaders use AI 8+ hours/week on real work. *Scholarly anchor: Holmstrom (1979) on moral hazard.* (BCG Trailblazers)
8. **Turn Compliance Into Deployment Advantage** — Audit infrastructure becomes competitive moat. *Scholarly anchor: North (1990) on institutional economics.* (JPMorgan, UBS)
10. **Productize Internal Operational Advantages** — Internal tools become revenue streams. *Scholarly anchor: Teece (1986) on profiting from technological innovation.* (Walmart, Salesforce)
11. **AI-Driven Management Delayering** — AI reduces the information-aggregation role of middle management, enabling flatter structures. *Scholarly anchor: Simon (1947) on bounded rationality.* (Amazon, Microsoft, UPS)

**Mechanism maturity lifecycle**: emerging → confirmed → widespread → deprecated. Mechanisms #2, #9, #12 were demoted to candidate status during the Feb 3 audit for insufficient evidence or definitional issues.

Additional candidate mechanisms remain under observation. Each mechanism links to specimens that demonstrate it.

### Field Insights

Cross-cutting findings that span multiple specimens, industries, or mechanisms. These are the field guide's key empirical contributions — **insights are never deleted**, only updated with new evidence or new insights added.

Insights are organized by theme (convergence, organizational-form, mechanism, workforce, methodology). The original 78 insights are archived in `synthesis/insights-archive-v1.json`. They have been consolidated into the **Analytical Framework** (see below).

### Analytical Framework (v0.2)

The project's converging theoretical layer. Full specification: `synthesis/ANALYTICAL-FRAMEWORK.md`.

**5 Analytical Primitives** (`synthesis/primitives.json`) — independent variables that predict structural choice:
- P1 Work Architecture Modularity (Conway/Colfer & Baldwin mirroring)
- P2 Work Output Measurability (Holmstrom multi-task)
- P3 Governance Structure (Aghion & Tirole formal/real authority)
- P4 Competitive/Institutional Context (North institutions, competitive dynamics)
- P5 Organizational Endowment (legacy systems, talent, culture, prior investment)

**10 Core Findings** (`synthesis/findings.json`) — empirical claims consolidated from 78 field insights, each with evidence, testable implications, and paper linkages. Finding maturity lifecycle: emerging → confirmed → contested.

**3 Latent Papers**: "Structure Follows Architecture" (P1-centered), "Moral Hazard of AI Transition" (P2-centered), "Purpose and Structure as Complements" (P3/P7-centered).

> **Exploration and Curiosity First.** The framework enriches the pipeline's analytical vocabulary without constraining what agents and researchers see. Evidence that contradicts or falls outside the framework receives the same weight as confirming evidence. All pipeline stages (research, curation, synthesis, purpose claims) have been updated with framework awareness at appropriate intensity levels — from light "antenna" at research through full analytical lens at synthesis.

### Tensions & Contingencies

Beyond mechanisms, the synthesis phase surfaces two additional analytical dimensions. **Tensions are now derived from primitive interactions** (e.g., T1 derives from P1×P3, T2 from P2×P4). T1 is the master tension; T4 retained with caveat. See `synthesis/tensions.json` for derivation details.

**Core Tensions** — Structural trade-offs that organizations navigate differently:

| Tension | Pole A | Pole B | What Drives the Choice |
|---------|--------|--------|------------------------|
| **Structural separation vs. Contextual integration** | Dedicated AI units, ring-fenced | AI embedded in everyone's role | Talent scarcity, coordination costs, cultural readiness |
| **Speed vs. Depth** | Fast deployment, learn in production | Careful validation before release | Regulatory exposure, error tolerance, competitive pressure |
| **Central vs. Distributed** | Centralized AI team, standards | Distributed ownership, local optimization | Coordination needs, domain specificity, talent distribution |
| **Named vs. Quiet** | Branded labs, visible investment | Unnamed adoption, quiet transformation | Signaling needs, acquisition competition, organizational politics |
| **Long vs. Short horizons** | Multi-year research bets | Quarterly delivery cycles | Capital access, competitive dynamics, leadership tenure |

**Key Contingencies** — Contextual factors that shape which structural choices work:

| Contingency | How It Shapes Structure |
|-------------|------------------------|
| **Regulatory intensity** | High regulation → more separation, audit trails, slower deployment |
| **Time-to-obsolescence** | Fast-moving markets → temporal ambidexterity, sprint-based exploration |
| **CEO tenure** | Long tenure → can protect long-horizon exploration; short tenure → execution focus |
| **Talent market position** | Talent-rich → can staff separate units; talent-scarce → contextual approaches |
| **Technical debt** | High debt → AI initiatives often stall; may need separate "greenfield" structures |
| **Environmental AI pull** | Strong external pressure (competitors, adversaries, customers) → faster adoption, more structural commitment; weak pull → risk of premature over-investment |

These tensions and contingencies help answer "it depends on what?" — the conditions under which different structural approaches succeed or struggle.

### About
- The botanist's approach
- Theoretical foundation (light touch)
- How specimens are researched and documented

---

## 8. What We Preserve from Existing Research

The existing research provides a strong empirical foundation:

### AI_Organizational_Models_Complete.docx → Core Taxonomy
The comprehensive reference document (285+ cases) provides:
- **6-Model Taxonomy** with sub-types — becomes Dimension 1 (Structural Model), expanded to 9 models with addition of Tiger Teams, Skunkworks, and AI-Native
- **77+ Named Product/Venture Labs** — richly documented specimens
- **50+ Unnamed/Informal cases** — the "quiet transformation" often missed
- **100+ Traditional Model examples by sector** — broad coverage
- **10 Key Strategic Insights** — becomes the Mechanisms section
- **Case Count Summary** — establishes empirical grounding

**Work required**: Add Dimension 2 (Ambidexterity Orientation) classification to each case; restructure into specimen card format.

### library/cases/ (52+ JSON files) → Specimen Details
The detailed case files provide:
- `content.whatItIs` + `content.howItWorks` → Description + Structural Mechanisms
- `content.coreInsight` + quotes → Quotes & Evidence
- `sources` → Sources
- Existing tagging → Starting point for classification

**Work required**: Reconcile with comprehensive document; add ambidexterity orientation; standardize format.

### library/designPrinciples/ (20 files) → Supplementary Mechanisms
Some design principles map to the 10 key mechanisms; others may be absorbed or retired:
- `protect-deviations` → Mechanism #1 (Protect Off-Strategy Work)
- `ceo-as-political-shield` → Part of #1 and #7
- `reward-fast-failure` → Mechanism #2 (Bonus Teams That Kill Projects)
- `consumer-grade-ux` → Mechanism #4

**Work required**: Map to 10 mechanisms; retire redundant principles; preserve unique insights.

### research papers/ambidexterity/ → Theoretical Grounding
The academic papers provide theoretical foundation:
- O'Reilly & Tushman papers for structural ambidexterity
- Gibson & Birkinshaw for contextual ambidexterity
- Jansen (2009) on integration mechanisms

**Work required**: Create brief, accessible summaries; link from About page.

---

## 9. Design Principles for the Site

### Show, Don't Prescribe
The site presents specimens and lets users draw their own conclusions. No "you should do X" language.

### Rich Detail Over Abstract Categories
Each specimen should feel like encountering a real organization. Specific mechanisms, actual quotes, concrete numbers.

### Sources Are Sacred
Every claim needs a source. Undated or unverifiable claims don't make it into the field guide.

### Every Fact Is Auditable
Observable markers and other specimen facts include inline `[source-id]` citations that link directly to the source. Readers can verify any claim by clicking through to the original source URL. The same standard applies to purpose claims (verbatim with source URL) and to observable markers (cited with `[source-id]`). Only synthesis-level insights (our own analytical observations) may be uncited.

### Let the Taxonomy Breathe
The classification system should help users navigate, not force specimens into ill-fitting boxes. "Hybrid" is a valid classification. Edge cases are noted.

### Accessible to Executives, Useful to Scholars
Light on jargon, heavy on practical detail. Theoretical connections available but not required to get value.

---

## 10. What's Different from the Original Spec

| Original Spec | Field Guide |
|--------------|-------------|
| 5 layers, 8 principles, 18 design principles | 2-dimension taxonomy (9 Structural Models × 3 Ambidexterity Orientations) |
| Prescriptive framework | Descriptive catalog |
| Conversation system with modes | Browse/search reference site |
| "Helps leadership teams develop stances" | "Documents how organizations actually structure this" |
| Artifact generation (Transformation Architecture Document) | No output artifact — the specimens ARE the value |
| Complex, interlocking concepts | Single organizing question (exploration/execution structure) |

---

## 11. Open Questions

1. **Scope**: Should we include contextual ambidexterity specimens, or focus exclusively on structural approaches?
   - *Status: RESOLVED — We include all three orientations (Structural, Contextual, Temporal). See `APP_STATE.md` for current orientation distribution.*

2. **Recency**: How do we handle specimens that may have evolved since documentation? Living documents vs. point-in-time snapshots?
   - *Status: RESOLVED — Stratigraphy model implemented. Specimens have `layers[]` array preserving historical evolution. Each layer is dated and sourced.*

3. **Failure cases**: Do we document organizations where structural approaches failed? (Valuable but harder to source)
   - *Status: OPEN — Not yet systematically addressed. Some specimens note tensions/failures (e.g., Google's delayed ChatGPT response, Databricks/Glean admitting 95% AI project failure rate).*

4. **Interactivity**: Any interactive elements beyond browse/filter? Comparison tool? Self-assessment?
   - *Status: BUILT — Situation Matcher (dimension-based + Claude chat advisor), Tension Map (D3 force-directed), Comparison View (side-by-side up to 4). All implemented in site prototype.*

5. **Updates**: What's the workflow for adding new specimens as organizations evolve?
   - *Status: RESOLVED — Three-phase skill workflow operational: `/research` → `/curate` → `/synthesize`. Source registry tracks coverage. Queue system tracks workflow state.*

---

## 12. Current State

> **⚠️ This section is intentionally sparse. For current counts (specimens, mechanisms, insights, model distribution, orientation distribution, source coverage, validation status), see `APP_STATE.md` — that file is updated at the end of every session and serves as the single source of truth for collection state.**

### Infrastructure Built

The three-phase workflow is fully operational, plus a fourth parallel track for purpose claims.

| Component | Location | Notes |
|-----------|----------|-------|
| **Specimen collection** | `specimens/*.json` | See `specimens/registry.json` for current count and model distribution |
| **Source registry** | `specimens/source-registry.json` | Tier 1 and Tier 2 sources tracked |
| **Research sessions** | `research/sessions/` | Growing with each research run |
| **Curation sessions** | `curation/sessions/` | Growing with each curation run |
| **Synthesis queue** | `curation/synthesis-queue.json` | Tracks specimens pending synthesis |
| **Mechanisms** | `synthesis/mechanisms.json` | Confirmed + candidate, with maturity lifecycle |
| **Insights** | `synthesis/insights.json` | Growing collection, never deleted (guardrail) |
| **Tensions** | `synthesis/tensions.json` | 5 core tensions (definitional) |
| **Contingencies** | `synthesis/contingencies.json` | 6 key contingencies (definitional) |
| **Skills** | `.claude/skills/` | `/research`, `/curate`, `/synthesize`, `/purpose-claims` |
| **Reference site** | `site/` | Working Next.js prototype with field journal |
| **Classification guardrails** | `skills/ambidexterity-curation/SKILL.md` | 7 guardrails in curation protocol |
| **Purpose claims** | `research/purpose-claims/registry.json` | Verbatim claim registry with v2.0 taxonomy (6 types) |
| **Purpose claims enrichment** | `research/purpose-claims/enrichment/*.json` | Per-specimen rhetorical profiles (100 files): claim type distribution, key findings, rhetorical patterns |
| **Spider/radar charts** | `site/components/visualizations/SpiderChart.tsx` | Visual rhetorical profiles on specimen pages and purpose claims browser |
| **Citation system** | `site/lib/utils/citations.ts` + `site/components/shared/CitedText.tsx` | Inline `[source-id]` markers for fact-level auditability |

### What Remains to Build

1. **Source URL backfill** — Many legacy sources have null URLs (see validator warnings for current count)
2. **Legacy case conversion** — Old-format files in `library/cases/` can be batch-converted via `scripts/convert-cases.js`
3. **Ongoing research** — Deep-scan backlog, Tier 2 sources, sector-specific deep dives
4. **Low-confidence specimens** — See `research/low-confidence-queue.json` for current queue
5. **Interactive synthesis** — Remaining specimen batches need collaborative placement (see `HANDOFF.md`)
5. **Site deployment** — Not yet deployed (runs locally only)
6. **Site Phase 4-6** — User features, research integration, polish (see APP_STATE.md)

---

## Appendix: Sample Specimen Classifications

### Example 1: Eli Lilly

**Classification**:
- **Structural Model**: Model 4 (Hub-and-Spoke) — decentralized 300-400 person hubs coordinated by central R&D leadership
- **Sub-type**: Secondary Model 5b (Venture Builder) via NVIDIA partnership
- **Ambidexterity Orientation**: Structural

**Specimen card** would include:
- Multiple 300-400 person hubs operating like biotechs, coordinated by central leadership
- 18+ year time horizon example (GLP-1 program: 2006 to Mounjaro)
- CEO Dave Ricks quote: "Middle management tends to squash deviations, but the deviations... make the next breakthrough"
- $1B NVIDIA co-innovation lab (January 2026)
- R&D investment: 20-25% of sales (~$120B revenue)
- **Mechanisms demonstrated**: #1 Protect Off-Strategy Work
- *Reclassified from M1 to M4 (taxonomy audit 2026-02): multiple distributed hubs with central coordination = Hub-and-Spoke*

### Example 2: Google X

**Classification**:
- **Structural Model**: Model 5b (Venture Builder)
- **Ambidexterity Orientation**: Structural

**Specimen card** would include:
- 100+ experiments annually, 2% graduation rate
- Graduated ventures (Waymo, Verily, Wing) consume 44% of budget after 5-6 years
- Teams get "applause, hugs, and high fives" for killing projects
- Pre-mortem practice: "Run at hard problems first"
- **Mechanisms demonstrated**: #2 Bonus Teams That Kill Projects

### Example 3: P&G (ChatPG)

**Classification**:
- **Structural Model**: Model 6b (Centralized-but-Unnamed)
- **Ambidexterity Orientation**: Contextual

**Specimen card** would include:
- 30,000+ active users
- 8,000 requests in first two hours of launch
- No formal lab structure or branding
- Rejected pilots in favor of mass deployment
- **Mechanisms demonstrated**: #5 Deploy to Thousands Before You Know What Works

### Example 4: Samsung C-Lab

**Classification**:
- **Structural Model**: Model 5a (Internal Incubator)
- **Ambidexterity Orientation**: Temporal

**Specimen card** would include:
- Permanent 13-year incubator (959 ventures since 2012)
- Employees leave current roles for full-year dedicated exploration
- 20% of projects spin off into independent companies
- Clear exit mechanism back to operations or out to venture
- **Mechanisms demonstrated**: Protected exploration with institutional permanence
- *Reclassified from M7 to M5a (taxonomy audit 2026-02): a permanent institutional program is not an ad hoc tiger team*

---

*This spec builds on empirical research originally documenting 285+ organizational cases. The specimen collection, confirmed mechanisms (each grounded in scholarly anchors), and field insights grow continuously through the three-phase skill workflow. A parallel purpose claims track collects verbatim leadership statements (v2.0 taxonomy: 6 types), with spider/radar chart visualizations for rhetorical profile comparison. Inline `[source-id]` citations provide fact-level auditability. See `APP_STATE.md` for current counts. The taxonomy is refined as specimens are documented and synthesized.*
